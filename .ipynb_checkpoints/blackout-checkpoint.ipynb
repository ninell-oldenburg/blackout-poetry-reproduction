{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e0f789",
   "metadata": {},
   "source": [
    "# Implementation of a Fine-Tuning exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c3935",
   "metadata": {},
   "source": [
    "Course taken from here: https://github.com/huggingface/notebooks/blob/main/examples/language_modeling.ipynb\n",
    "\n",
    "Dataset taken from kaggle, https://www.kaggle.com/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e27609f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98129d0c03d344f2b33fe47a1edd25ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d48402f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.22.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "23442b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data_8k.json')\n",
    "df.to_csv('data_8k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8830ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2632c3da93050a9b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /Users/nell/.cache/huggingface/datasets/csv/default-2632c3da93050a9b/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf6e9f491f746e19ba6b7f93bc0064c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b11312b031430db3a652c1f0806bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41174d3c4b174d43ad33eb582afd7a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/nell/.cache/huggingface/datasets/csv/default-2632c3da93050a9b/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Features\n",
    "import datasets\n",
    "\n",
    "ds_train = load_dataset(\"csv\", data_files=\"data_8k.csv\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08272d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['passage', 'poem', 'indices', 'ppl-gpt2', 'grammar-check'],\n",
      "    num_rows: 8599\n",
      "})\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['passage', 'poem', 'indices', 'ppl-gpt2', 'grammar-check'],\n",
      "        num_rows: 6019\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['passage', 'poem', 'indices', 'ppl-gpt2', 'grammar-check'],\n",
      "        num_rows: 2580\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds_train)\n",
    "ds_train = ds_train.train_test_split(test_size=0.3)\n",
    "print()\n",
    "print(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38123ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passage': 'Closed eyes can see,\\nlips upon lips.\\nThoughts empty of resistence,\\nbodies filled with urgency.\\nHunger turns into a beast,\\nwithout hesitation.\\nCloser than close,\\nlips brush lips.\\nElectricity surges,\\nlightning strikes the sky.\\nTongues seductively dance,\\nharmonous with the sounds of lust.\\nPassion consumes,\\nlips tasting, feeling, teasing, yearning,\\nurgent to satisfy the starvation of time.\\nTongues gently licking wet lips,\\nsucking.\\nBodies are alive,\\nburing with heat.\\nAll reason cast aside.\\nThe sheer pleasure of a oneness,\\nfeverish,  passionate, wanting more.\\nMore pleasure,\\nmore hot steamy,\\nwet tongues flickering.\\nSlowly parting gazing eye to eye,\\nthe purist truths exposed.\\nNothing hidden in the instant\\nthat we first kissed.',\n",
       " 'poem': 'closed eyes a beast surges with the sounds',\n",
       " 'indices': '[0, 1, 18, 19, 29, 38, 39, 40]',\n",
       " 'ppl-gpt2': 1282.2120501958,\n",
       " 'grammar-check': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train['train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64591767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passage': 'Love is delicate,\\nAs like the petals of a rose\\nLove is innocent,\\nlike the purity of a rose\\nLove is delightful,\\nlike the smell of a rose\\nLove hurts,\\nlike the thorns of a rose.\\nLove begins,\\nlike a seed.\\nand like a rose,\\nIf you water it;\\nIt grows.',\n",
       " 'poem': 'is the petals of a rose',\n",
       " 'indices': '[1, 5, 6, 7, 8, 9]',\n",
       " 'ppl-gpt2': 77.412094514,\n",
       " 'grammar-check': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train['test'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1d9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e10a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>poem</th>\n",
       "      <th>indices</th>\n",
       "      <th>ppl-gpt2</th>\n",
       "      <th>grammar-check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanksgiving, dark of the moon.\\r\\r\\nNothing down here in the underworld but vague shapes and black holes,   \\r\\r\\nHeaven resplendent but virtual\\r\\r\\nAbove me,\\r\\r\\n                    trees stripped and triple-wired like Irish harps.   \\r\\r\\nLights on Pantops and Free Bridge mirror the eastern sky.   \\r\\r\\nUnder the bridge is the river,\\r\\r\\n                                                     the red Rivanna.\\r\\r\\nUnder the river’s redemption, it says in the book,   \\r\\r\\nIt says in the book,Through water and fire the whole place becomes purified,   \\r\\r\\nThe visible by the visible, the hidden by what is hidden.</td>\n",
       "      <td>dark shapes resplendent is under the redemption</td>\n",
       "      <td>[1, 13, 18, 43, 49, 50, 52]</td>\n",
       "      <td>487.559394</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(SUGGESTED INSCRIPTION PROBABLY NOT SUGGESTED BY THE COMMITTEE)\\r\\r\\n\\r\\r\\n\\r\\r\\n\\r\\r\\nThe hucksters haggle in the mart\\r\\r\\nThe cars and carts go by;\\r\\r\\nSenates and schools go droning on;\\r\\r\\nFor dead things cannot die.\\r\\r\\nA storm stooped on the place of tombs\\r\\r\\nWith bolts to blast and rive;\\r\\r\\nBut these be names of many men\\r\\r\\nThe lightning found alive.\\r\\r\\nIf usurers rule and rights decay\\r\\r\\nAnd visions view once more\\r\\r\\nGreat Carthage like a golden shell\\r\\r\\nGape hollow on the shore,\\r\\r\\nStill to the last of crumbling time\\r\\r\\nUpon this stone be read\\r\\r\\nHow many men of England died\\r\\r\\nTo prove they were not dead.</td>\n",
       "      <td>inscription hucksters the dead things on the place</td>\n",
       "      <td>[1, 9, 12, 27, 28, 34, 35, 36]</td>\n",
       "      <td>616.310195</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highlight Actions\\r\\r\\nEnable or disable annotations\\r\\r\\n\\r\\r\\n\\r\\r\\n\\r\\r\\n\\r\\r\\nSometimes I thinkSometimes I think In a 2001 interview, Elizabeth Alexander noted, “As for the ‘banner headline’, ‘Race’, I always loved the way that my grandfather, and to a lesser extent my parents, used the word race to talk about ‘the race’ — meaning, of course, black people — as a thing that they could imagine, a body of people that we could imagine, that you could almost get your arms around, that the race was something tangible and palpable.” about Great-Uncle Paul who left Tuskegee,\\r\\r\\nAlabama</td>\n",
       "      <td>highlight actions a lesser extent as a thing</td>\n",
       "      <td>[0, 1, 12, 35, 36, 55, 56, 57]</td>\n",
       "      <td>1153.673945</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Words torn, unseen, unseemly, scenesome far suburb’s mall lot Summer’s theme: this year’s humid—to sweat is to know—pen squeezed too tight yields ink as blood or pus so the phrase scraped, removed offending thine eye: “Outsource Bush” Against which, insource what? Who will do it? Most terrible predicate—high above mountains snow-capped even in August in-flight motion picture Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>torn this ink as the phrase</td>\n",
       "      <td>[1, 11, 22, 23, 28, 29]</td>\n",
       "      <td>768.452431</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Europe: 1944\\r\\r\\r\\nas regarded from a great distance\\r\\r\\n\\r\\r\\n\\r\\r\\n\\r\\r\\nImpersonal the aim\\r\\r\\nWhere giant movements tend;\\r\\r\\nEach man appears the same;\\r\\r\\nFriend vanishes from friend.\\r\\r\\nIn the long path of lead\\r\\r\\nThat changes place like light\\r\\r\\nNo shape of hand or head\\r\\r\\nMeans anything tonight.\\r\\r\\nOnly the common will\\r\\r\\nFor which explosion spoke;\\r\\r\\nAnd stiff on field and hill\\r\\r\\nThe dark blood of the folk.</td>\n",
       "      <td>distance movements each same vanishes from the path</td>\n",
       "      <td>[7, 13, 15, 19, 21, 22, 25, 27]</td>\n",
       "      <td>910.617694</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yes, faith can lift a mountain from its base!\\nYes, faith can turn a river off its course;\\nYes, faith can win an impossible race!\\nYes, faith can calm a lion as he roars!\\nSure, faith can do impossible a thing!\\nSure, faith can hold a marriage till the end!\\nSure, faith can well a happy ending bring!\\nSure, faith can truly iron bars too bend!\\nTrue faith can make a friendship very strong!\\nTrue faith unites two lovers tie the knot!\\nTrue faith can make miles look like one furlong!\\nTrue faith can win a war although ill-fought!\\nNone can afford to lose faith since their birth,\\nAnd faith in God is what we need on earth.</td>\n",
       "      <td>sure sure a happy ending</td>\n",
       "      <td>[34, 41, 45, 55, 56]</td>\n",
       "      <td>430.197442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>why does it hurt when i smile?\\ncut when i call your name?\\ni think i'll sit alone a while,\\nand dream of life without pain.\\nwhy am i better depressed?\\nit seems to fit so well.\\nmy fresh cuts still undressed,\\nhigh from the bloods smell.\\nwhy do you run from me?\\ni'm really not that bad.\\nopen your heart and now see,\\nthere's a reason that i'm sad.\\ni'm sorry i cant tell you,\\nbut please don't run away!\\ndon't you know what its like to be hated too?\\nto fear each second of the day?\\nyou act like i'm a killer,\\nand like i'm after you.\\nits just like in a thriller,\\nyour the perfect victim too.</td>\n",
       "      <td>fresh cuts the bloods from that heart</td>\n",
       "      <td>[38, 39, 44, 45, 51, 56, 60]</td>\n",
       "      <td>482.457393</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nature’s beauty show.\\nnear Tokyo in the spring\\nguaranteed to please.\\navenues of cherry trees.\\nsoft spring breezes blow\\nsetting pink blossoms dancing\\non the cherry trees\\ntheir sweet perfumes they release.\\nlovers stroll below\\nunaware completely free\\nto just wander to and fro.\\nall that they can see\\ntheir own private paradise\\nwhere the blossom never dies,\\n10-Apr-08\\nChoka sonnet</td>\n",
       "      <td>beauty avenues cherry trees on the cherry</td>\n",
       "      <td>[1, 11, 13, 14, 23, 24, 25]</td>\n",
       "      <td>1311.128147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A woman with a burning flame\\nDeep covered through the years\\nWith ashes.  Ah! she hid it deep,\\nAnd smothered it with tears.\\n\\nSometimes a baleful light would rise\\nFrom out the dusky bed,\\nAnd then the woman hushed it quick\\nTo slumber on, as dead.\\n\\nAt last the weary war was done\\nThe tapers were alight,\\nAnd with a sigh of victory\\nShe breathed a soft—good-night!</td>\n",
       "      <td>deep tears a light as the war</td>\n",
       "      <td>[17, 22, 24, 26, 44, 48, 50]</td>\n",
       "      <td>520.593299</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You sit left to me,\\nYou don't wanna see,\\nWhat's really inside me.\\nDo you want to hurt me?\\nYou could tell it everyone!\\nWould it make you feel better?\\nYou don't know anything about me.\\nMy new name for you is 'ABC'\\nI don't need lipstick for attention,\\nI also never owned extentions.\\nThe only problem I ever had was you\\nand what you used to do.\\nAnd the last thing I tell you about me,\\nis why you're so much weaker than me:\\nYou only blance on a tightrope that's lying on the floor,\\nI'm doing the same but over a huge gorge.\\n©</td>\n",
       "      <td>name extentions problem was about a tightrope</td>\n",
       "      <td>[38, 53, 56, 60, 75, 89, 90]</td>\n",
       "      <td>850.798879</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(ds_train['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b835a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69de9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc8d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"passage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6253f844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3701c95c806c4637a558c7c14da1bcc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df6d66604cb44e8b457b485816b2864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15b5983e7604987ac4e70c87e2d441e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f32f6af0b1d4e4da8279067ccdfed6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1722 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578a7c0bbd0a4929b1ed59eaa8bfcfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3f64a7da3e46269b684ff62e1fb81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44979892a30b4655af7dd7245c410a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c45ef3f04c4e6d894dfbf4a4713aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1606 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = ds_train.map(tokenize_function, batched=True, num_proc=4, \n",
    "                                  remove_columns=[\"passage\", \"poem\", 'indices', 'ppl-gpt2', 'grammar-check'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aab7b472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'But Mary kept all these things, and pondered them in her heart.\\r\\r\\nA strategy of continence, avoidance, mule-headedness, and hope.\\r\\r\\nThe next assassin, brush fire, or virus swerves this way, head-on collision;\\r\\r\\nWe see it coming and can’t divert\\u2009—\\u2009the path too crowded with pilgrims.\\r\\r\\nBy the side of the road to Calvary blooms a mustard bush.\\r\\r\\nIt never means to do anything but propagate.\\r\\r\\nIt sees the centuries winnow themselves in and out,\\r\\r\\nAnd hears itself appropriated for a parable.\\r\\r\\nIt keeps all these things, and ponders them in its heart\\r\\r\\nWhile casting savior seeds generation after generation.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b908999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2aad229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a5a0d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964544095a2d46288f6a080bc1d71270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aa4d2c927f486494eb6eec78f4b377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc533c7f5c74f229704ce0c81574353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e06cd96d85b466ea873dcb0fb1a5c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25f1834db244416bb432610a430cdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d5978752bf42199ba5b6ff0f493c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1aaa046aac45459fd260f8c896cb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b0b7fb1be74b7a99bf0c33d06aa06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "669c7ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe red night clouds, the afterbirth,\\nthe snail shell whorls of them.\\n\\nThe unborns we named:\\n\\nBeinn Narnain, Ben Vane, Beinn Ime,\\nBen Vorlich, and Beinn BhuidheBut Mary kept all these things, and pondered them in her heart.\\r\\r\\nA strategy of continence, avoidance, mule-headedness, and hope.\\r\\r\\nThe next assassin, brush fire, or virus swerves this way, head-on collision;\\r\\r\\nWe see it coming and can’t divert'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8cb539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55486947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "544c48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    "    hub_token = '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',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db7f32f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nell/Documents/GitHub/blackout-poetry-reproduction/distilgpt2-finetuned-wikitext2 is already a clone of https://huggingface.co/ninellninell/distilgpt2-finetuned-wikitext2. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7835d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6603\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2478\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='2478' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  32/2478 00:27 < 37:19, 1.09 it/s, Epoch 0.04/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c443e0",
   "metadata": {},
   "source": [
    "# Masked Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e1ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilroberta-base\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "tokenized_datasets = ds_train.map(tokenize_function, batched=True, num_proc=4, \n",
    "                                  remove_columns=[\"passage\", \"poem\", 'indices', 'ppl-gpt2', 'grammar-check'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a29b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1809838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    "    hub_token = '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',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc026c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "# taking the samples and batching them in tensors\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41940bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ca485",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108c0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
